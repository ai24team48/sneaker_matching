# Документация проекта
## 1. Структура проекта
Проект включает в себя следующие файлы и директории:

- `models/` - директория с обученными моделями
- `service/` - директория с сервисами.
    - `prediction_pipeline.py` — файл для обработки пайплайна предсказаний.
    - `training_pipeline.py` — файл для обработки пайплайна обучения.
    - `train_classes.py` — файл для классов, используемых в обучении
- `api/` - директория с кодом для API для /predict и /fit, вызывается из main.py
    - `predictions.py`
    - `training.py`
- `data/` - директория с тестовыми данными. Представлен небольшой экземпляр, так как все данные для обучения весят 10 гб.
    - Описание всех данных лежит в `data_info.md` https://github.com/ai24team48/sneaker_matching/blob/main/data_info.txt
- `streamlit.py` - файл для запуска Streamlit-приложения.
- `main.py` - основной файл для запуска FastAPI-сервера.
- `requirement.txt` - файл с зависимостями.
- `checkpoints.md` - файл с планом разработки проекта
- `notebooks/` - файл, где лежат ноутбуки с обучением моделей, а также eda с данными
    - `NN_model.ipynb` - Модель, которая используется в fast api.
    - `catboost.py` - 


### FastAPI сервер и Streamlit

Основной функционал API реализован в FastAPI-сервере. 
- В функции мейн есть три сервиса: root - проверяет, что сервис запущен, list_models - информация о моделях их слои, кол параметров, active_models - 
- функцию больше необходимая на будущее, когда список основных моделей будет больше одного, также в main есть два роутера на api/prediction - выполняет
- функцию предсказания, которая хранится в service/prediction_pipline (на вход подается pickle файл), на основе которого нужно сделать предсказания,
- данный файл продается в prediction_pipline, где на основе обученной модели и хранящейся в models считаются предсказания и в качестве csv подаются в
- виде ответа от сервера
- Api/training - функция необходимая, для того чтобы показать, что обучение работает и на маленьком объеме данных можно обучить модель,
- входные параметры по типы размер батча, кол эпох, флаг обучения или до обучения, имя модели, под которым сохраняться веса - входные данные,
- pkl файл с данными для обучения, которые позже отправляются в service/training_pipline и там разбиваются на тест и трейниг и происходит обучение модели

Для его запуска нужно выполнить следующую команду:
### Как запустить проект:
#### 1.Создайте вирт. окружение:
- python -m venv venv
#### 2.Установите зависимости:
- pip install -r requirement.txt
#### 3.Запустите сервер и приложение:
Используйте следующие команды
- python main.py
- streamlit run streamlit.py
- Это поднимет сервер FastAPI, который будет доступен по адресу http://127.0.0.1:8000
- После запуска приложение будет доступно в браузере, обычно по адресу http://localhost:8501

Также можно запустить через докер
- docker-compose up --build  

## Описание функционала

- Функционал сервера позволяет закинуть файл pickle для создания предсказания, являются ли объекты матчем или нет.
- Функционал позволяет выполнить eda файла с описанием товара.

Для более структурного хранения файлов и для возможности их открытия данные были разделены.

Поэтому для предсказания и для eda нужно загружать разные файлы.

Демонстрация работы сайта лежит здесь
https://disk.yandex.ru/i/p9nLzansVsZRCQ
