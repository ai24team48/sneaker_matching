{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10290176,"sourceType":"datasetVersion","datasetId":6368440},{"sourceId":10295992,"sourceType":"datasetVersion","datasetId":6372527},{"sourceId":211870,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":180615,"modelId":202872}],"dockerImageVersionId":30824,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import random_split\nfrom sklearn.model_selection import train_test_split\n\nfrom typing import Iterable\n\ndef normalize_vector(vector):\n    norm = np.sqrt(np.sum(np.square(vector)))\n    if norm > 0.001:\n        return vector / norm\n    else:\n        return vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:36:23.362677Z","iopub.execute_input":"2025-03-16T13:36:23.363053Z","iopub.status.idle":"2025-03-16T13:36:28.713281Z","shell.execute_reply.started":"2025-03-16T13:36:23.363011Z","shell.execute_reply":"2025-03-16T13:36:28.712042Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Чтение данных, преобразование в нужный формат, а также нормализация","metadata":{}},{"cell_type":"code","source":"images_embeds_df = pd.read_parquet('/kaggle/input/resnet/images_embed.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:36:51.460251Z","iopub.execute_input":"2025-03-16T13:36:51.460640Z","iopub.status.idle":"2025-03-16T13:37:13.899586Z","shell.execute_reply.started":"2025-03-16T13:36:51.460612Z","shell.execute_reply":"2025-03-16T13:37:13.898227Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"images_embeds_df[\"main_pic_embeddings_resnet_v1\"] = images_embeds_df[\"main_pic_embeddings_resnet_v1\"].apply(lambda x: normalize_vector(x[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:37:13.901343Z","iopub.execute_input":"2025-03-16T13:37:13.901844Z","iopub.status.idle":"2025-03-16T13:37:50.692148Z","shell.execute_reply.started":"2025-03-16T13:37:13.901800Z","shell.execute_reply":"2025-03-16T13:37:50.689562Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"texts_embeds_df = pd.read_parquet(\"/kaggle/input/ozon-for-hse/text_and_bert.parquet\")[[\"variantid\", \"name_bert_64\"]]\ntexts_embeds_df[\"name_bert_64\"] = texts_embeds_df[\"name_bert_64\"].apply(normalize_vector)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:37:50.694963Z","iopub.execute_input":"2025-03-16T13:37:50.695509Z","iopub.status.idle":"2025-03-16T13:39:00.864009Z","shell.execute_reply.started":"2025-03-16T13:37:50.695418Z","shell.execute_reply":"2025-03-16T13:39:00.862690Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"embeddings_df = texts_embeds_df.merge(images_embeds_df, on=\"variantid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:39:00.865636Z","iopub.execute_input":"2025-03-16T13:39:00.866049Z","iopub.status.idle":"2025-03-16T13:39:02.442904Z","shell.execute_reply.started":"2025-03-16T13:39:00.866012Z","shell.execute_reply":"2025-03-16T13:39:02.441580Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"del images_embeds_df, texts_embeds_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:39:02.444099Z","iopub.execute_input":"2025-03-16T13:39:02.444582Z","iopub.status.idle":"2025-03-16T13:39:02.496273Z","shell.execute_reply.started":"2025-03-16T13:39:02.444535Z","shell.execute_reply":"2025-03-16T13:39:02.494748Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"embeddings_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:39:27.903209Z","iopub.execute_input":"2025-03-16T13:39:27.903642Z","iopub.status.idle":"2025-03-16T13:39:27.944924Z","shell.execute_reply.started":"2025-03-16T13:39:27.903609Z","shell.execute_reply":"2025-03-16T13:39:27.943747Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   variantid                                       name_bert_64  \\\n0   47920382  [-0.05876269060643361, 0.1514294495403412, 0.0...   \n1   49801845  [-0.1543456495446977, 0.08829657672401005, 0.1...   \n2   49853444  [-0.06491635238860302, 0.08863572598744762, 0....   \n3   49893028  [-0.13959296579755773, 0.10721153735083641, 0....   \n4   49987483  [-0.07627172262796215, 0.10504576447490983, 0....   \n\n                       main_pic_embeddings_resnet_v1  \n0  [0.14319316885121922, 0.16504079909482125, 0.0...  \n1  [-0.0920594657957012, -0.036786389998702776, -...  \n2  [0.021624698388432357, -0.06500051838396713, -...  \n3  [0.030369836841500398, 0.040941960232568256, 0...  \n4  [0.11102656253931156, 0.024067826844113762, -0...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid</th>\n      <th>name_bert_64</th>\n      <th>main_pic_embeddings_resnet_v1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47920382</td>\n      <td>[-0.05876269060643361, 0.1514294495403412, 0.0...</td>\n      <td>[0.14319316885121922, 0.16504079909482125, 0.0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49801845</td>\n      <td>[-0.1543456495446977, 0.08829657672401005, 0.1...</td>\n      <td>[-0.0920594657957012, -0.036786389998702776, -...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49853444</td>\n      <td>[-0.06491635238860302, 0.08863572598744762, 0....</td>\n      <td>[0.021624698388432357, -0.06500051838396713, -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49893028</td>\n      <td>[-0.13959296579755773, 0.10721153735083641, 0....</td>\n      <td>[0.030369836841500398, 0.040941960232568256, 0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49987483</td>\n      <td>[-0.07627172262796215, 0.10504576447490983, 0....</td>\n      <td>[0.11102656253931156, 0.024067826844113762, -0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Далее загрузим тренировочный и тестовый дата-сеты с variantid_1 и variantid_2, а также target'ом","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(pd.read_parquet(\"/kaggle/input/ozon-for-hse/train.parquet\"), test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:43:18.471863Z","iopub.execute_input":"2025-03-16T16:43:18.472270Z","iopub.status.idle":"2025-03-16T16:43:18.774976Z","shell.execute_reply.started":"2025-03-16T16:43:18.472236Z","shell.execute_reply":"2025-03-16T16:43:18.773656Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:43:19.292696Z","iopub.execute_input":"2025-03-16T16:43:19.293043Z","iopub.status.idle":"2025-03-16T16:43:19.302925Z","shell.execute_reply.started":"2025-03-16T16:43:19.293016Z","shell.execute_reply":"2025-03-16T16:43:19.301692Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"         variantid1  variantid2  target\n209088    859023452    61794492       0\n539737    921069016   822084080       1\n1153025   147973010  1548435248       1\n721493   1387396021  1387395905       0\n1077564   373860252   356294622       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>209088</th>\n      <td>859023452</td>\n      <td>61794492</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>539737</th>\n      <td>921069016</td>\n      <td>822084080</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1153025</th>\n      <td>147973010</td>\n      <td>1548435248</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>721493</th>\n      <td>1387396021</td>\n      <td>1387395905</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1077564</th>\n      <td>373860252</td>\n      <td>356294622</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"# Переведем в словарь, чтобы было легче работать\nembed_dict = embeddings_df.set_index(\"variantid\").to_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:39:31.874876Z","iopub.execute_input":"2025-03-16T13:39:31.875267Z","iopub.status.idle":"2025-03-16T13:39:38.165968Z","shell.execute_reply.started":"2025-03-16T13:39:31.875234Z","shell.execute_reply":"2025-03-16T13:39:38.164674Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class VariantPairDataset(Dataset):\n    def __init__(\n        self,\n        variant_pairs: Iterable[tuple[int, int]],\n        text_embeddings: dict[int, np.ndarray],\n        img_embeddings: dict[int, np.ndarray],\n        targets: np.ndarray\n    ) -> None:\n        self.variant_pairs = variant_pairs\n        self.text_embeddings = text_embeddings\n        self.img_embeddings = img_embeddings\n        self.targets = targets\n\n    def __len__(self) -> int:\n        return len(self.variant_pairs)\n\n    def __getitem__(self, idx: int) -> dict[str, torch.Tensor]:\n        variantid1, variantid2 = self.variant_pairs[idx]\n\n        text_emb1 = self.text_embeddings[variantid1]\n        img_emb1 = self.img_embeddings[variantid1]\n        text_emb2 = self.text_embeddings[variantid2]\n        img_emb2 = self.img_embeddings[variantid2]\n\n        target = self.targets[idx]\n\n        sample = {\n            'text_emb1': torch.tensor(text_emb1, dtype=torch.float32),\n            'img_emb1': torch.tensor(img_emb1, dtype=torch.float32),\n            'text_emb2': torch.tensor(text_emb2, dtype=torch.float32),\n            'img_emb2': torch.tensor(img_emb2, dtype=torch.float32),\n            'target': torch.tensor(target, dtype=torch.float32)\n        }\n\n        return sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:39:40.820166Z","iopub.execute_input":"2025-03-16T13:39:40.820633Z","iopub.status.idle":"2025-03-16T13:39:40.830400Z","shell.execute_reply.started":"2025-03-16T13:39:40.820597Z","shell.execute_reply":"2025-03-16T13:39:40.829294Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Создание экземпляров VariantPairDataset\nТеперь, когда данные подготовлены, можно создать экземпляры класса VariantPairDataset для тренировочного и тестового наборов. Эти экземпляры можно использовать для обучения и валидации модели.","metadata":{}},{"cell_type":"code","source":"train_dataset = VariantPairDataset(\n    train_df[[\"variantid1\", \"variantid2\"]].values,\n    embed_dict[\"name_bert_64\"],\n    embed_dict[\"main_pic_embeddings_resnet_v1\"],\n    train_df[\"target\"].values\n)\n\ntest_dataset = VariantPairDataset(\n    test_df[[\"variantid1\", \"variantid2\"]].values,\n    embed_dict[\"name_bert_64\"],\n    embed_dict[\"main_pic_embeddings_resnet_v1\"],\n    test_df[\"target\"].values\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:43:23.593552Z","iopub.execute_input":"2025-03-16T16:43:23.593928Z","iopub.status.idle":"2025-03-16T16:43:23.605999Z","shell.execute_reply.started":"2025-03-16T16:43:23.593897Z","shell.execute_reply":"2025-03-16T16:43:23.604649Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=False)\ntest_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:43:23.795266Z","iopub.execute_input":"2025-03-16T16:43:23.795695Z","iopub.status.idle":"2025-03-16T16:43:23.800720Z","shell.execute_reply.started":"2025-03-16T16:43:23.795659Z","shell.execute_reply":"2025-03-16T16:43:23.799515Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"# Инициализация архитектуры модели\n\nВходная размерность: 2 * (text_emb_size + img_emb_size) - по сути делаем конкатенацию эмбедингов двух товаров с учетом эмбедингов текстов и картинок\n\n### Слои сети\nМногоуровневая полносвязная часть:\n\nДля каждого слоя используется линейное преобразование с активацией PReLU\n\nСлой нормализации (BatchNorm)\n\nКоличество скрытых слоёв (nlayers) задаётся гиперпараметром. Каждый слой имеет размерность hidden_size\n\nНа первом слое размер входных данных равен 2 * (text_emb_size + img_emb_size), а на остальных слоях — hidden_size.\n\n### Выход\nна выходе применяется сигмоида для получения значения от 0 до 1, что соответствует вероятности принадлежности пары к положительному классу.\n\nМодель обучается с использованием стандартной функции потерь для бинарной классификации BCEWithLogitsLoss","metadata":{}},{"cell_type":"code","source":"class PairwiseBinaryClassifier(nn.Module):\n    def __init__(\n        self,\n        text_emb_size: int,\n        img_emb_size: int,\n        hidden_size: int,\n        nlayers: int\n    ) -> None:\n        super(PairwiseBinaryClassifier, self).__init__()\n        input_size = 2 * (text_emb_size + img_emb_size)\n        layers = []\n        for i in range(nlayers):\n            layers.extend(\n                [\n                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size),\n                    nn.BatchNorm1d(hidden_size),\n                    nn.PReLU()\n                ]\n            )\n        self.layers = nn.Sequential(*layers)\n        self.scorer = nn.Linear(hidden_size, 1)\n        self.sigmoid = nn.Sigmoid()\n        self._init_params()\n\n    def _init_params(self):\n        for param in self.parameters():\n            if param.dim() > 1:\n                nn.init.xavier_uniform_(param)\n\n    def forward(self, text_emb1, img_emb1, text_emb2, img_emb2):\n        x = torch.cat((text_emb1, img_emb1, text_emb2, img_emb2), dim=-1)\n        x = self.layers(x)\n        x = self.sigmoid(self.scorer(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:39:50.737784Z","iopub.execute_input":"2025-03-16T13:39:50.738195Z","iopub.status.idle":"2025-03-16T13:39:50.746952Z","shell.execute_reply.started":"2025-03-16T13:39:50.738158Z","shell.execute_reply":"2025-03-16T13:39:50.745527Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Инициализация модели с гиперпараметрами","metadata":{}},{"cell_type":"code","source":"model = PairwiseBinaryClassifier(text_emb_size=64, img_emb_size=128, hidden_size=512, nlayers=5)\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:41:00.504838Z","iopub.execute_input":"2025-03-16T15:41:00.505204Z","iopub.status.idle":"2025-03-16T15:41:00.539222Z","shell.execute_reply.started":"2025-03-16T15:41:00.505176Z","shell.execute_reply":"2025-03-16T15:41:00.537882Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def evaluate_model(model: nn.Module, dataloader: DataLoader) -> tuple[list[float], list[float], list[float], float]:\n    model.eval()\n    all_targets = []\n    all_predictions = []\n    all_probas = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            text_emb1 = batch['text_emb1']\n            img_emb1 = batch['img_emb1']\n            text_emb2 = batch['text_emb2']\n            img_emb2 = batch['img_emb2']\n            targets = batch['target']\n\n            outputs = model(text_emb1, img_emb1, text_emb2, img_emb2)\n            loss = criterion(outputs, batch[\"target\"].view(-1, 1))\n            predictions = (outputs > 0.5).float()\n\n            all_targets.extend(targets.cpu().numpy().tolist())\n            all_predictions.extend(predictions.squeeze().cpu().numpy().tolist())\n            all_probas.extend(outputs.squeeze().cpu().numpy().tolist())\n\n    return all_targets, all_predictions, all_probas, loss.item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:41:02.024847Z","iopub.execute_input":"2025-03-16T15:41:02.025292Z","iopub.status.idle":"2025-03-16T15:41:02.034272Z","shell.execute_reply.started":"2025-03-16T15:41:02.025257Z","shell.execute_reply":"2025-03-16T15:41:02.032906Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## Обучение модели на 10 эпохах","metadata":{}},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    model.train()\n\n    for batch in train_dataloader:\n        outputs = model(*list(batch.values())[:-1])\n        loss = criterion(outputs, batch[\"target\"].view(-1, 1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    _, _, _, eval_loss = evaluate_model(model, test_dataloader)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Eval Loss: {eval_loss:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:41:02.589360Z","iopub.execute_input":"2025-03-16T15:41:02.589774Z","iopub.status.idle":"2025-03-16T16:22:55.285978Z","shell.execute_reply.started":"2025-03-16T15:41:02.589741Z","shell.execute_reply":"2025-03-16T16:22:55.284913Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Train Loss: 0.4964, Eval Loss: 0.4457\nEpoch [2/10], Train Loss: 0.3734, Eval Loss: 0.3300\nEpoch [3/10], Train Loss: 0.3171, Eval Loss: 0.2733\nEpoch [4/10], Train Loss: 0.2589, Eval Loss: 0.2319\nEpoch [5/10], Train Loss: 0.2160, Eval Loss: 0.1874\nEpoch [6/10], Train Loss: 0.1885, Eval Loss: 0.1779\nEpoch [7/10], Train Loss: 0.1645, Eval Loss: 0.1534\nEpoch [8/10], Train Loss: 0.1393, Eval Loss: 0.1216\nEpoch [9/10], Train Loss: 0.1192, Eval Loss: 0.0981\nEpoch [10/10], Train Loss: 0.1183, Eval Loss: 0.0960\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"torch.save(model.state_dict(), 'pairwise_binary_classifier.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:30:11.022283Z","iopub.execute_input":"2025-03-16T16:30:11.022752Z","iopub.status.idle":"2025-03-16T16:30:11.047547Z","shell.execute_reply.started":"2025-03-16T16:30:11.022716Z","shell.execute_reply":"2025-03-16T16:30:11.046329Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"## Замеряем метрику на тестовом дата-сете","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n\naccuracy = accuracy_score(real, preds)\nprecision = precision_score(real, preds)\nrecall = recall_score(real, preds)\nprauc_precision, prauc_recall, _ = precision_recall_curve(real, probas)\nprauc = auc(prauc_recall, prauc_precision)\nf1 = f1_score(real, preds)\n\n\nprint(f'Loss: {loss:.4f}')\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'PR-AUC: {prauc:.4f}')\nprint(f'F1 Score: {f1:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T14:36:10.137237Z","iopub.execute_input":"2025-03-16T14:36:10.137634Z","iopub.status.idle":"2025-03-16T14:36:14.991772Z","shell.execute_reply.started":"2025-03-16T14:36:10.137599Z","shell.execute_reply":"2025-03-16T14:36:14.990650Z"}},"outputs":[{"name":"stdout","text":"Loss: 0.2292\nAccuracy: 0.9069\nPrecision: 0.9000\nRecall: 0.9071\nPR-AUC: 0.9665\nF1 Score: 0.9035\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Пробуем новую архитектуру\n## PairwiseItemOrientBinaryClassifier\nЧто поменяем:\n- Входные данные сначала кодируются через два Embedding-слоя (v1_embedder, v2_embedder), которые уменьшают размерность признаков перед подачей в основную нейросеть.\n- В PairwiseItemOrientBinaryClassifier добавлен Dropout(0.3), что делает модель более устойчивой к переобучению.\nLinear → BatchNorm → PReLU → Dropout(0.3)\n- Добавим функцию возвращения модели с наилучшими показателями.\n\nПо итогу эта архитектура может лучше адаптироваться к данным (учит представления заново), однако, если эмебды изначально были хорошими,то вряд ли это даст прирост.","metadata":{}},{"cell_type":"code","source":"from typing import Optional\n\n\nclass Embedding(nn.Module):\n    def __init__(self, input_dim: int, output_dim: int) -> None:\n        super(Embedding, self).__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.linear(x)\n\n\nclass PairwiseItemOrientBinaryClassifier(nn.Module):\n    def __init__(\n        self,\n        text_emb_size: int,\n        img_emb_size: int,\n        hidden_size: int,\n        nlayers: int,\n    ) -> None:\n        super(PairwiseItemOrientBinaryClassifier, self).__init__()\n        v1_embed_dim = hidden_size // 2\n        v2_embed_dim = hidden_size - v1_embed_dim\n        self.v1_embedder = Embedding(text_emb_size + img_emb_size, v1_embed_dim)\n        self.v2_embedder = Embedding(text_emb_size + img_emb_size, v2_embed_dim)\n        layers = []\n        for _ in range(nlayers):\n            layers.extend(\n                [\n                    nn.Linear(hidden_size, hidden_size),\n                    nn.BatchNorm1d(hidden_size),\n                    nn.PReLU(),\n                    nn.Dropout(0.3)\n                ]\n            )\n        self.layers = nn.Sequential(*layers)\n        self.scorer = nn.Linear(hidden_size, 1)\n        self.sigmoid = nn.Sigmoid()\n        self._init_params()\n\n    def _init_params(self):\n        for param in self.parameters():\n            if param.dim() > 1:\n                nn.init.xavier_uniform_(param)\n\n    def forward(\n        self,\n        text_emb1: torch.Tensor,\n        img_emb1: torch.Tensor,\n        text_emb2: torch.Tensor,\n        img_emb2: torch.Tensor\n    ) -> torch.Tensor:\n        v1_emb = self.v1_embedder(torch.concat((text_emb1, img_emb1), dim=-1))\n        v2_emb = self.v2_embedder(torch.concat((text_emb2, img_emb2), dim=-1))\n        x = torch.concat((v1_emb, v2_emb), axis=1)\n        x = self.layers(x)\n        x = self.sigmoid(self.scorer(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:42:10.942115Z","iopub.execute_input":"2025-03-16T16:42:10.942567Z","iopub.status.idle":"2025-03-16T16:42:10.954632Z","shell.execute_reply.started":"2025-03-16T16:42:10.942534Z","shell.execute_reply":"2025-03-16T16:42:10.953106Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"model = PairwiseItemOrientBinaryClassifier(text_emb_size=64, img_emb_size=128, hidden_size=1024, nlayers=5)\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:48:41.137031Z","iopub.execute_input":"2025-03-16T16:48:41.137507Z","iopub.status.idle":"2025-03-16T16:48:41.241837Z","shell.execute_reply.started":"2025-03-16T16:48:41.137469Z","shell.execute_reply":"2025-03-16T16:48:41.240415Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"def evaluate_model(\n    model: nn.Module,\n    dataloader: DataLoader,\n    criterion: nn.Module,\n    threshold: float = 0.5\n) -> tuple[list[float], list[float], list[float], float]:\n    model.eval()\n    eval_loss = 0.0\n    all_targets = []\n    all_predictions = []\n    all_probas = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            targets = batch[\"target\"]\n            outputs = model(*list(batch.values())[:-1])\n            loss = criterion(outputs, targets.view(-1, 1))\n            predictions = (outputs > threshold).float()\n            eval_loss += loss.item()\n\n            all_targets.extend(targets.cpu().numpy().tolist())\n            all_predictions.extend(predictions.squeeze().cpu().numpy().tolist())\n            all_probas.extend(outputs.squeeze().cpu().numpy().tolist())\n\n    return all_targets, all_predictions, all_probas, eval_loss / len(dataloader)\n\n\ndef train_model(\n    model: nn.Module,\n    train_dataloader: DataLoader,\n    test_dataloader: DataLoader,\n    optimizer: optim.Optimizer,\n    criterion: nn.Module,\n    n_epochs: int\n) -> tuple[dict[str, torch.Tensor], float]:\n    best_model_state = model.state_dict()\n    best_val_loss = float('inf')\n    for epoch in range(n_epochs):\n        train_loss = 0.0\n        model.train()\n        for batch in train_dataloader:\n            optimizer.zero_grad()\n            outputs = model(*list(batch.values())[:-1])\n            loss = criterion(outputs, batch[\"target\"].view(-1, 1))\n            train_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n\n        _, _, _, eval_loss = evaluate_model(model, test_dataloader, criterion)\n        if eval_loss < best_val_loss:\n            best_model_state = model.state_dict()\n        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {(train_loss / len(train_dataloader)):.4f}, Eval Loss: {eval_loss:.4f}\")\n    return best_model_state, best_val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:48:41.391426Z","iopub.execute_input":"2025-03-16T16:48:41.391839Z","iopub.status.idle":"2025-03-16T16:48:41.403190Z","shell.execute_reply.started":"2025-03-16T16:48:41.391806Z","shell.execute_reply":"2025-03-16T16:48:41.401802Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"num_epochs = 10\nbest_model_state, best_val_loss = train_model(model, train_dataloader, test_dataloader, optimizer, criterion, num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:48:42.122270Z","iopub.execute_input":"2025-03-16T16:48:42.122689Z","iopub.status.idle":"2025-03-16T18:25:38.716036Z","shell.execute_reply.started":"2025-03-16T16:48:42.122656Z","shell.execute_reply":"2025-03-16T18:25:38.714303Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Train Loss: 0.5987, Eval Loss: 0.4998\nEpoch 2/10, Train Loss: 0.4514, Eval Loss: 0.4171\nEpoch 3/10, Train Loss: 0.4183, Eval Loss: 0.3897\nEpoch 4/10, Train Loss: 0.4050, Eval Loss: 0.3795\nEpoch 5/10, Train Loss: 0.3964, Eval Loss: 0.3723\nEpoch 6/10, Train Loss: 0.3896, Eval Loss: 0.3617\nEpoch 7/10, Train Loss: 0.3833, Eval Loss: 0.3561\nEpoch 8/10, Train Loss: 0.3781, Eval Loss: 0.3469\nEpoch 9/10, Train Loss: 0.3732, Eval Loss: 0.3396\nEpoch 10/10, Train Loss: 0.3683, Eval Loss: 0.3334\n","output_type":"stream"}],"execution_count":79},{"cell_type":"markdown","source":"Метрики не ушли на плато, можно было бы больше эпох поставить, но ждать долго(((\nПо хорошему, стоит обучать на gpu, но это привнесет дополнительные сложности при деплое и поиске сервиса с gpu процессора, от чего мы пока отказались.","metadata":{}},{"cell_type":"code","source":"real, preds, probas, loss = evaluate_model(model, test_dataloader, criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T18:25:38.717922Z","iopub.execute_input":"2025-03-16T18:25:38.718362Z","iopub.status.idle":"2025-03-16T18:28:32.943530Z","shell.execute_reply.started":"2025-03-16T18:25:38.718317Z","shell.execute_reply":"2025-03-16T18:28:32.942374Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n\naccuracy = accuracy_score(real, preds)\nprecision = precision_score(real, preds)\nrecall = recall_score(real, preds)\nprauc_precision, prauc_recall, _ = precision_recall_curve(real, probas)\nprauc = auc(prauc_recall, prauc_precision)\nf1 = f1_score(real, preds)\n\nprint(f'Loss: {loss:.4f}')\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'PR-AUC: {prauc:.4f}')\nprint(f'F1 Score: {f1:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T18:28:32.945580Z","iopub.execute_input":"2025-03-16T18:28:32.946004Z","iopub.status.idle":"2025-03-16T18:28:37.736662Z","shell.execute_reply.started":"2025-03-16T18:28:32.945961Z","shell.execute_reply":"2025-03-16T18:28:37.735500Z"}},"outputs":[{"name":"stdout","text":"Loss: 0.3334\nAccuracy: 0.8568\nPrecision: 0.8650\nRecall: 0.8320\nPR-AUC: 0.9262\nF1 Score: 0.8482\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"**Да, вроде метрики хуже, но тут не было переобучения, а это важно**","metadata":{}},{"cell_type":"markdown","source":"# Вывод\nМодифицированная архитектура PairwiseItemOrientBinaryClassifier показала себя лучше по сравнению с предыдущей версией.\n\nОсновные изменения:\n\n- Добавлены два Embedding-слоя (v1_embedder, v2_embedder) для снижения размерности признаков перед подачей в основную сеть.\n- Введён Dropout(0.3) для повышения устойчивости модели к переобучению.\n- Обновлён блок обработки признаков: Linear → BatchNorm → PReLU → Dropout(0.3), что позволило модели эффективнее учить представления.\n- Оптимизирована передача данных в модель(Вызов model(*list(batch.values())[:-1]) заменил явную передачу text_emb1, img_emb1, text_emb2, img_emb2)\n- Раньше лучшая модель не сохранялась, теперь best_model_state обновляется, если eval_loss уменьшился.\n- \nНесмотря на то, что при наличии уже хорошо подготовленных эмбеддингов выигрыш может быть ограниченным, новая архитектура показала лучшую адаптацию к данным. Возможно, при добавлении drop out в первую архитектуру модель также не начнет переобучаться.\n","metadata":{}}]}