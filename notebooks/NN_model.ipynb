{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10290176,"sourceType":"datasetVersion","datasetId":6368440},{"sourceId":10295992,"sourceType":"datasetVersion","datasetId":6372527}],"dockerImageVersionId":30824,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import random_split\nfrom sklearn.model_selection import train_test_split\n\nfrom typing import Iterable\n\ndef normalize_vector(vector):\n    norm = np.sqrt(np.sum(np.square(vector)))\n    if norm > 0.001:\n        return vector / norm\n    else:\n        return vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:46:57.565990Z","iopub.execute_input":"2024-12-27T17:46:57.566280Z","iopub.status.idle":"2024-12-27T17:47:02.778956Z","shell.execute_reply.started":"2024-12-27T17:46:57.566254Z","shell.execute_reply":"2024-12-27T17:47:02.777534Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Чтение данных, преобразование в нужный формат, а также нормализация","metadata":{}},{"cell_type":"code","source":"images_embeds_df = pd.read_parquet('/kaggle/input/resnet/images_embed.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:49:55.441304Z","iopub.execute_input":"2024-12-27T17:49:55.441745Z","iopub.status.idle":"2024-12-27T17:50:18.110626Z","shell.execute_reply.started":"2024-12-27T17:49:55.441711Z","shell.execute_reply":"2024-12-27T17:50:18.109465Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"images_embeds_df[\"main_pic_embeddings_resnet_v1\"] = images_embeds_df[\"main_pic_embeddings_resnet_v1\"].apply(lambda x: normalize_vector(x[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:50:18.112145Z","iopub.execute_input":"2024-12-27T17:50:18.112514Z","iopub.status.idle":"2024-12-27T17:50:47.718729Z","shell.execute_reply.started":"2024-12-27T17:50:18.112485Z","shell.execute_reply":"2024-12-27T17:50:47.715537Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"texts_embeds_df = pd.read_parquet(\"/kaggle/input/ozon-for-hse/text_and_bert.parquet\")[[\"variantid\", \"name_bert_64\"]]\ntexts_embeds_df[\"name_bert_64\"] = texts_embeds_df[\"name_bert_64\"].apply(normalize_vector)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:50:47.725541Z","iopub.execute_input":"2024-12-27T17:50:47.726218Z","iopub.status.idle":"2024-12-27T17:51:55.794306Z","shell.execute_reply.started":"2024-12-27T17:50:47.726172Z","shell.execute_reply":"2024-12-27T17:51:55.792673Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"embeddings_df = texts_embeds_df.merge(images_embeds_df, on=\"variantid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:51:55.796375Z","iopub.execute_input":"2024-12-27T17:51:55.796689Z","iopub.status.idle":"2024-12-27T17:51:57.374022Z","shell.execute_reply.started":"2024-12-27T17:51:55.796663Z","shell.execute_reply":"2024-12-27T17:51:57.372865Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"del images_embeds_df, texts_embeds_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:51:57.375260Z","iopub.execute_input":"2024-12-27T17:51:57.375668Z","iopub.status.idle":"2024-12-27T17:51:57.429027Z","shell.execute_reply.started":"2024-12-27T17:51:57.375622Z","shell.execute_reply":"2024-12-27T17:51:57.427779Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"embeddings_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:51:57.430155Z","iopub.execute_input":"2024-12-27T17:51:57.430638Z","iopub.status.idle":"2024-12-27T17:51:57.484717Z","shell.execute_reply.started":"2024-12-27T17:51:57.430572Z","shell.execute_reply":"2024-12-27T17:51:57.483367Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   variantid                                       name_bert_64  \\\n0   47920382  [-0.05876269060643361, 0.1514294495403412, 0.0...   \n1   49801845  [-0.1543456495446977, 0.08829657672401005, 0.1...   \n2   49853444  [-0.06491635238860302, 0.08863572598744762, 0....   \n3   49893028  [-0.13959296579755773, 0.10721153735083641, 0....   \n4   49987483  [-0.07627172262796215, 0.10504576447490983, 0....   \n\n                       main_pic_embeddings_resnet_v1  \n0  [0.14319316885121922, 0.16504079909482125, 0.0...  \n1  [-0.0920594657957012, -0.036786389998702776, -...  \n2  [0.021624698388432357, -0.06500051838396713, -...  \n3  [0.030369836841500398, 0.040941960232568256, 0...  \n4  [0.11102656253931156, 0.024067826844113762, -0...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid</th>\n      <th>name_bert_64</th>\n      <th>main_pic_embeddings_resnet_v1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47920382</td>\n      <td>[-0.05876269060643361, 0.1514294495403412, 0.0...</td>\n      <td>[0.14319316885121922, 0.16504079909482125, 0.0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49801845</td>\n      <td>[-0.1543456495446977, 0.08829657672401005, 0.1...</td>\n      <td>[-0.0920594657957012, -0.036786389998702776, -...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49853444</td>\n      <td>[-0.06491635238860302, 0.08863572598744762, 0....</td>\n      <td>[0.021624698388432357, -0.06500051838396713, -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49893028</td>\n      <td>[-0.13959296579755773, 0.10721153735083641, 0....</td>\n      <td>[0.030369836841500398, 0.040941960232568256, 0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49987483</td>\n      <td>[-0.07627172262796215, 0.10504576447490983, 0....</td>\n      <td>[0.11102656253931156, 0.024067826844113762, -0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Далее загрузим тренировочный и тестовый дата-сеты с variantid_1 и variantid_2, а также target'ом","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(pd.read_parquet(\"/kaggle/input/ozon-for-hse/train.parquet\"), test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:51:57.485997Z","iopub.execute_input":"2024-12-27T17:51:57.486436Z","iopub.status.idle":"2024-12-27T17:51:57.978675Z","shell.execute_reply.started":"2024-12-27T17:51:57.486399Z","shell.execute_reply":"2024-12-27T17:51:57.977361Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Переведем в словарь, чтобы было легче работать\nembed_dict = embeddings_df.set_index(\"variantid\").to_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:51:57.982547Z","iopub.execute_input":"2024-12-27T17:51:57.982911Z","iopub.status.idle":"2024-12-27T17:52:04.276398Z","shell.execute_reply.started":"2024-12-27T17:51:57.982868Z","shell.execute_reply":"2024-12-27T17:52:04.275185Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class VariantPairDataset(Dataset):\n    def __init__(\n        self,\n        variant_pairs: Iterable[tuple[int, int]],\n        text_embeddings: dict[int, np.ndarray],\n        img_embeddings: dict[int, np.ndarray],\n        targets: np.ndarray\n    ) -> None:\n        self.variant_pairs = variant_pairs\n        self.text_embeddings = text_embeddings\n        self.img_embeddings = img_embeddings\n        self.targets = targets\n\n    def __len__(self) -> int:\n        return len(self.variant_pairs)\n\n    def __getitem__(self, idx: int) -> dict[str, torch.Tensor]:\n        variantid1, variantid2 = self.variant_pairs[idx]\n\n        text_emb1 = self.text_embeddings[variantid1]\n        img_emb1 = self.img_embeddings[variantid1]\n        text_emb2 = self.text_embeddings[variantid2]\n        img_emb2 = self.img_embeddings[variantid2]\n\n        target = self.targets[idx]\n\n        sample = {\n            'text_emb1': torch.tensor(text_emb1, dtype=torch.float32),\n            'img_emb1': torch.tensor(img_emb1, dtype=torch.float32),\n            'text_emb2': torch.tensor(text_emb2, dtype=torch.float32),\n            'img_emb2': torch.tensor(img_emb2, dtype=torch.float32),\n            'target': torch.tensor(target, dtype=torch.float32)\n        }\n\n        return sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:52:04.278786Z","iopub.execute_input":"2024-12-27T17:52:04.279133Z","iopub.status.idle":"2024-12-27T17:52:04.287812Z","shell.execute_reply.started":"2024-12-27T17:52:04.279091Z","shell.execute_reply":"2024-12-27T17:52:04.286631Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Создание экземпляров VariantPairDataset\nТеперь, когда данные подготовлены, можно создать экземпляры класса VariantPairDataset для тренировочного и тестового наборов. Эти экземпляры можно использовать для обучения и валидации модели.","metadata":{}},{"cell_type":"code","source":"train_dataset = VariantPairDataset(\n    train_df[[\"variantid1\", \"variantid2\"]].values,\n    embed_dict[\"name_bert_64\"],\n    embed_dict[\"main_pic_embeddings_resnet_v1\"],\n    train_df[\"target\"].values\n)\n\ntest_dataset = VariantPairDataset(\n    test_df[[\"variantid1\", \"variantid2\"]].values,\n    embed_dict[\"name_bert_64\"],\n    embed_dict[\"main_pic_embeddings_resnet_v1\"],\n    test_df[\"target\"].values\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:52:04.289220Z","iopub.execute_input":"2024-12-27T17:52:04.289657Z","iopub.status.idle":"2024-12-27T17:52:04.320417Z","shell.execute_reply.started":"2024-12-27T17:52:04.289590Z","shell.execute_reply":"2024-12-27T17:52:04.318856Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=True)\ntest_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:52:04.321736Z","iopub.execute_input":"2024-12-27T17:52:04.322142Z","iopub.status.idle":"2024-12-27T17:52:04.329001Z","shell.execute_reply.started":"2024-12-27T17:52:04.322097Z","shell.execute_reply":"2024-12-27T17:52:04.327376Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Инициализация архитектуры модели\n\nВходная размерность: 2 * (text_emb_size + img_emb_size) - по сути делаем конкатенацию эмбедингов двух товаров с учетом эмбедингов текстов и картинок\n\n### Слои сети\nМногоуровневая полносвязная часть:\n\nДля каждого слоя используется линейное преобразование с активацией PReLU\n\nСлой нормализации (BatchNorm)\n\nКоличество скрытых слоёв (nlayers) задаётся гиперпараметром. Каждый слой имеет размерность hidden_size\n\nНа первом слое размер входных данных равен 2 * (text_emb_size + img_emb_size), а на остальных слоях — hidden_size.\n\n### Выход\nна выходе применяется сигмоида для получения значения от 0 до 1, что соответствует вероятности принадлежности пары к положительному классу.\n\nМодель обучается с использованием стандартной функции потерь для бинарной классификации BCEWithLogitsLoss","metadata":{}},{"cell_type":"code","source":"class PairwiseBinaryClassifier(nn.Module):\n    def __init__(\n        self,\n        text_emb_size: int,\n        img_emb_size: int,\n        hidden_size: int,\n        nlayers: int\n    ) -> None:\n        super(PairwiseBinaryClassifier, self).__init__()\n        input_size = 2 * (text_emb_size + img_emb_size)\n        layers = []\n        for i in range(nlayers):\n            layers.extend(\n                [\n                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size),\n                    nn.BatchNorm1d(hidden_size),\n                    nn.PReLU()\n                ]\n            )\n        self.layers = nn.Sequential(*layers)\n        self.scorer = nn.Linear(hidden_size, 1)\n        self.sigmoid = nn.Sigmoid()\n        self._init_params()\n\n    def _init_params(self):\n        for param in self.parameters():\n            if param.dim() > 1:\n                nn.init.xavier_uniform_(param)\n\n    def forward(self, text_emb1, img_emb1, text_emb2, img_emb2):\n        x = torch.cat((text_emb1, img_emb1, text_emb2, img_emb2), dim=-1)\n        x = self.layers(x)\n        x = self.sigmoid(self.scorer(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:52:04.330375Z","iopub.execute_input":"2024-12-27T17:52:04.330911Z","iopub.status.idle":"2024-12-27T17:52:04.347791Z","shell.execute_reply.started":"2024-12-27T17:52:04.330869Z","shell.execute_reply":"2024-12-27T17:52:04.346467Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Инициализация модели с гиперпараметрами","metadata":{}},{"cell_type":"code","source":"model = PairwiseBinaryClassifier(text_emb_size=64, img_emb_size=128, hidden_size=512, nlayers=5)\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:52:04.348984Z","iopub.execute_input":"2024-12-27T17:52:04.349415Z","iopub.status.idle":"2024-12-27T17:52:06.023372Z","shell.execute_reply.started":"2024-12-27T17:52:04.349374Z","shell.execute_reply":"2024-12-27T17:52:06.022415Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def evaluate_model(model: nn.Module, dataloader: DataLoader) -> tuple[list[float], list[float], list[float], float]:\n    model.eval()\n    all_targets = []\n    all_predictions = []\n    all_probas = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            text_emb1 = batch['text_emb1']\n            img_emb1 = batch['img_emb1']\n            text_emb2 = batch['text_emb2']\n            img_emb2 = batch['img_emb2']\n            targets = batch['target']\n\n            outputs = model(text_emb1, img_emb1, text_emb2, img_emb2)\n            loss = criterion(outputs, batch[\"target\"].view(-1, 1))\n            predictions = (outputs > 0.5).float()\n\n            all_targets.extend(targets.cpu().numpy().tolist())\n            all_predictions.extend(predictions.squeeze().cpu().numpy().tolist())\n            all_probas.extend(outputs.squeeze().cpu().numpy().tolist())\n\n    return all_targets, all_predictions, all_probas, loss.item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:52:06.024394Z","iopub.execute_input":"2024-12-27T17:52:06.024925Z","iopub.status.idle":"2024-12-27T17:52:06.033029Z","shell.execute_reply.started":"2024-12-27T17:52:06.024894Z","shell.execute_reply":"2024-12-27T17:52:06.031805Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Обучение модели на 10 эпохах","metadata":{}},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    model.train()\n\n    for batch in train_dataloader:\n        outputs = model(*list(batch.values())[:-1])\n        loss = criterion(outputs, batch[\"target\"].view(-1, 1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    _, _, _, eval_loss = evaluate_model(model, test_dataloader)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Eval Loss: {eval_loss:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:52:06.034194Z","iopub.execute_input":"2024-12-27T17:52:06.034574Z","iopub.status.idle":"2024-12-27T18:32:26.246341Z","shell.execute_reply.started":"2024-12-27T17:52:06.034533Z","shell.execute_reply":"2024-12-27T18:32:26.244819Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Train Loss: 0.4810, Eval Loss: 0.4963\nEpoch [2/10], Train Loss: 0.4017, Eval Loss: 0.4201\nEpoch [3/10], Train Loss: 0.3998, Eval Loss: 0.3667\nEpoch [4/10], Train Loss: 0.3453, Eval Loss: 0.3646\nEpoch [5/10], Train Loss: 0.3350, Eval Loss: 0.3444\nEpoch [6/10], Train Loss: 0.3577, Eval Loss: 0.3130\nEpoch [7/10], Train Loss: 0.3097, Eval Loss: 0.3014\nEpoch [8/10], Train Loss: 0.3380, Eval Loss: 0.2668\nEpoch [9/10], Train Loss: 0.3198, Eval Loss: 0.2510\nEpoch [10/10], Train Loss: 0.2655, Eval Loss: 0.2326\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"torch.save(model.state_dict(), 'pairwise_binary_classifier.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:32:26.247603Z","iopub.execute_input":"2024-12-27T18:32:26.247973Z","iopub.status.idle":"2024-12-27T18:32:26.265832Z","shell.execute_reply.started":"2024-12-27T18:32:26.247944Z","shell.execute_reply":"2024-12-27T18:32:26.264650Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Замеряем метрику на тестовом дата-сете","metadata":{}},{"cell_type":"code","source":"real, preds, probas, loss = evaluate_model(model, test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:32:26.266994Z","iopub.execute_input":"2024-12-27T18:32:26.267294Z","iopub.status.idle":"2024-12-27T18:34:00.015389Z","shell.execute_reply.started":"2024-12-27T18:32:26.267267Z","shell.execute_reply":"2024-12-27T18:34:00.014251Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n\n# Compute evaluation metrics\naccuracy = accuracy_score(real, preds)\nprecision = precision_score(real, preds)\nrecall = recall_score(real, preds)\nprauc_precision, prauc_recall, _ = precision_recall_curve(real, probas)\nprauc = auc(prauc_recall, prauc_precision)\nf1 = f1_score(real, preds)\n\n\nprint(f'Loss: {loss:.4f}')\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'PR-AUC: {prauc:.4f}')\nprint(f'F1 Score: {f1:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:34:00.016517Z","iopub.execute_input":"2024-12-27T18:34:00.016868Z","iopub.status.idle":"2024-12-27T18:34:04.401584Z","shell.execute_reply.started":"2024-12-27T18:34:00.016839Z","shell.execute_reply":"2024-12-27T18:34:04.400725Z"}},"outputs":[{"name":"stdout","text":"Loss: 0.2326\nAccuracy: 0.9066\nPrecision: 0.8865\nRecall: 0.9241\nPR-AUC: 0.9683\nF1 Score: 0.9049\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nsampled_df = test_df.sample(n=15, random_state=42)\n\nsampled_variant_pairs = sampled_df[[\"variantid1\", \"variantid2\", \"target\"]]\n\nsampled_variant_pairs[\"name_bert_64_1\"] = sampled_variant_pairs[\"variantid1\"].map(embed_dict[\"name_bert_64\"])\nsampled_variant_pairs[\"name_bert_64_2\"] = sampled_variant_pairs[\"variantid2\"].map(embed_dict[\"name_bert_64\"])\nsampled_variant_pairs[\"main_pic_embeddings_resnet_v1_1\"] = sampled_variant_pairs[\"variantid1\"].map(embed_dict[\"main_pic_embeddings_resnet_v1\"])\nsampled_variant_pairs[\"main_pic_embeddings_resnet_v1_2\"] = sampled_variant_pairs[\"variantid2\"].map(embed_dict[\"main_pic_embeddings_resnet_v1\"])\n\nsampled_variant_pairs.to_csv(\"sampled_test_data_with_embeddings.csv\", index=False)\nsampled_variant_pairs.to_pickle(\"sampled_test_data_with_embeddings.pkl\")\nprint(\"CSV файл с 15 семплами и embeddings создан!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:53:11.366633Z","iopub.execute_input":"2024-12-27T18:53:11.367216Z","iopub.status.idle":"2024-12-27T18:53:17.092786Z","shell.execute_reply.started":"2024-12-27T18:53:11.367173Z","shell.execute_reply":"2024-12-27T18:53:17.090905Z"}},"outputs":[{"name":"stdout","text":"CSV файл с 15 семплами и embeddings создан!\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\nsampled_df = pd.read_pickle(\"/kaggle/working/sampled_test_data_with_embeddings.pkl\")\n\ntext_embeddings_sampled = embed_dict[\"name_bert_64\"]\nimg_embeddings_sampled = embed_dict[\"main_pic_embeddings_resnet_v1\"]\n\nsampled_variant_pairs = sampled_df[[\"variantid1\", \"variantid2\"]].values\ntargets_sampled = sampled_df[\"target\"].values\n\nsampled_dataset = VariantPairDataset(\n    variant_pairs=sampled_variant_pairs,\n    text_embeddings=text_embeddings_sampled,\n    img_embeddings=img_embeddings_sampled,\n    targets=targets_sampled\n)\n\n# Даталоадер для предсказания\nsampled_dataloader = DataLoader(sampled_dataset, batch_size=15, shuffle=False)\n\n# Оценка модели\ndef evaluate_model(model: nn.Module, dataloader: DataLoader) -> tuple[list[float], list[float], list[float], float]:\n    model.eval()\n    all_targets = []\n    all_predictions = []\n    all_probas = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            text_emb1 = batch['text_emb1']\n            img_emb1 = batch['img_emb1']\n            text_emb2 = batch['text_emb2']\n            img_emb2 = batch['img_emb2']\n            targets = batch['target']\n\n            # Прогоняем данные через модель\n            outputs = model(text_emb1, img_emb1, text_emb2, img_emb2)\n            loss = criterion(outputs, batch[\"target\"].view(-1, 1))\n            predictions = (outputs > 0.5).float()\n\n            all_targets.extend(targets.cpu().numpy().tolist())\n            all_predictions.extend(predictions.squeeze().cpu().numpy().tolist())\n            all_probas.extend(outputs.squeeze().cpu().numpy().tolist())\n\n    return all_targets, all_predictions, all_probas, loss.item()\n\n# Получаем результаты предсказаний\nreal, preds, probas, loss = evaluate_model(model, sampled_dataloader)\n\n# Метрики\naccuracy = accuracy_score(real, preds)\nf1 = f1_score(real, preds)\nroc_auc = roc_auc_score(real, probas)\n\nprint(f\"Loss: {loss}\")\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"F1 Score: {f1}\")\nprint(f\"ROC AUC: {roc_auc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:53:24.271316Z","iopub.execute_input":"2024-12-27T18:53:24.271697Z","iopub.status.idle":"2024-12-27T18:53:24.300869Z","shell.execute_reply.started":"2024-12-27T18:53:24.271668Z","shell.execute_reply":"2024-12-27T18:53:24.299745Z"}},"outputs":[{"name":"stdout","text":"Loss: 0.2778693437576294\nAccuracy: 0.8666666666666667\nF1 Score: 0.8000000000000002\nROC AUC: 0.96\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"sampled_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:53:30.216827Z","iopub.execute_input":"2024-12-27T18:53:30.217182Z","iopub.status.idle":"2024-12-27T18:53:30.283373Z","shell.execute_reply.started":"2024-12-27T18:53:30.217155Z","shell.execute_reply":"2024-12-27T18:53:30.282038Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"        variantid1  variantid2  target  \\\n586673   447116673   447276570       0   \n110057   588412848  1169982188       0   \n402656  1538045212  1260308147       1   \n603778   624543430   643995467       1   \n990986   549717139   770507056       0   \n409047   649797520   879623472       0   \n702968   520370280   519611246       0   \n159390  1378854094  1479216673       0   \n669154   559634167  1068285114       1   \n962862  1198430731  1320472216       1   \n188630  1050279370  1057322612       1   \n154425  1434804241  1434785206       0   \n405418  1446269122  1451536066       0   \n490819   147167695   656496769       0   \n162204   862443433   862986797       0   \n\n                                           name_bert_64_1  \\\n586673  [-0.11546845693788657, 0.11879767000499351, 0....   \n110057  [-0.08414979233219054, 0.1594500221920774, 0.1...   \n402656  [-0.06026564376806319, 0.06466471119274592, 0....   \n603778  [-0.10795983864026687, 0.11143058981914807, 0....   \n990986  [-0.05780336186312863, 0.10871770418453706, 0....   \n409047  [-0.12076712039491183, 0.07852172420462776, 0....   \n702968  [-0.11797401983607729, 0.10413861452454366, 0....   \n159390  [-0.15941642796337185, 0.09956636748152727, 0....   \n669154  [-0.19295330385439521, 0.1060335238520659, 0.1...   \n962862  [-0.16471791832722063, 0.13700978647391915, 0....   \n188630  [-0.10568100505825985, 0.11672703286742532, 0....   \n154425  [-0.1652294224511481, 0.1664451347303791, 0.13...   \n405418  [-0.12249209733134717, 0.14965457011623776, 0....   \n490819  [-0.09343938430993842, 0.16067352633038368, 0....   \n162204  [-0.1644600735300163, 0.14104117149291884, 0.1...   \n\n                                           name_bert_64_2  \\\n586673  [-0.12460829199407925, 0.12305943289675993, 0....   \n110057  [-0.06564694978218584, 0.16773359051108175, 0....   \n402656  [-0.06026564376806319, 0.06466471119274592, 0....   \n603778  [-0.10795983864026687, 0.11143058981914807, 0....   \n990986  [-0.10695534967774047, 0.10274007141308132, 0....   \n409047  [-0.06267111313383358, 0.10102431998347174, 0....   \n702968  [-0.10429043371336227, 0.15591572990719407, 0....   \n159390  [-0.14322157790637444, 0.09359274834060663, 0....   \n669154  [-0.1421385807586221, 0.10561073868838532, 0.1...   \n962862  [-0.14285859017240532, 0.10894745194399306, 0....   \n188630  [-0.10568100505825985, 0.11672703286742532, 0....   \n154425  [-0.1601871410059333, 0.1503487376351924, 0.09...   \n405418  [-0.12449717778328495, 0.1161154961997902, 0.0...   \n490819  [-0.1216826261401168, 0.14150558613359662, 0.1...   \n162204  [-0.1320074528937805, 0.094743007297204, 0.175...   \n\n                          main_pic_embeddings_resnet_v1_1  \\\n586673  [-0.052273153188848204, 0.10378567635655774, -...   \n110057  [0.0028043567225936416, 0.08737022878496849, 0...   \n402656  [0.013333064400492953, 0.04302197479255666, -0...   \n603778  [-0.1444987461840761, 0.012642815029058228, 0....   \n990986  [-0.11563188984453558, -0.0300171418274068, 0....   \n409047  [0.026176950310800598, 0.07444865815055808, 0....   \n702968  [0.15868388728853233, -0.12677397737166818, 0....   \n159390  [-0.09069716768735359, 0.0842488682283678, 0.0...   \n669154  [0.095310759569876, 0.020021074148214812, -0.0...   \n962862  [0.15620091271218106, -0.09836465236844918, -0...   \n188630  [0.09069506140904349, -0.04152337680339512, 0....   \n154425  [0.03214607775076375, 0.07641763451645232, -0....   \n405418  [-0.024547983898651593, 0.011389824063666409, ...   \n490819  [0.05849160579397191, -0.01331073934266062, 0....   \n162204  [-0.07075008790592768, 0.09369094553234529, 0....   \n\n                          main_pic_embeddings_resnet_v1_2  \n586673  [-0.052273153188848204, 0.10378567635655774, -...  \n110057  [0.020681329515193053, 0.09606176851262922, 0....  \n402656  [0.027618132749886747, 0.043863263628167844, 0...  \n603778  [-0.1444987461840761, 0.012642815029058228, 0....  \n990986  [-0.14109791208323372, -0.09175968737285321, 0...  \n409047  [0.09139589627693984, 0.0473513305769275, -0.0...  \n702968  [0.15863902201190758, -0.12766167187419677, 0....  \n159390  [-0.034625219577910406, 0.03753115899603996, -...  \n669154  [0.095310759569876, 0.020021074148214812, -0.0...  \n962862  [0.15622335486895064, -0.09833839443225638, -0...  \n188630  [0.09069506140904349, -0.04152337680339512, 0....  \n154425  [-0.024973559088412093, 0.10590774794461999, -...  \n405418  [-0.022082243277048247, -0.07765947746200852, ...  \n490819  [0.05849160579397191, -0.01331073934266062, 0....  \n162204  [-0.12192321576079582, 0.11373922332080083, 0....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n      <th>target</th>\n      <th>name_bert_64_1</th>\n      <th>name_bert_64_2</th>\n      <th>main_pic_embeddings_resnet_v1_1</th>\n      <th>main_pic_embeddings_resnet_v1_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>586673</th>\n      <td>447116673</td>\n      <td>447276570</td>\n      <td>0</td>\n      <td>[-0.11546845693788657, 0.11879767000499351, 0....</td>\n      <td>[-0.12460829199407925, 0.12305943289675993, 0....</td>\n      <td>[-0.052273153188848204, 0.10378567635655774, -...</td>\n      <td>[-0.052273153188848204, 0.10378567635655774, -...</td>\n    </tr>\n    <tr>\n      <th>110057</th>\n      <td>588412848</td>\n      <td>1169982188</td>\n      <td>0</td>\n      <td>[-0.08414979233219054, 0.1594500221920774, 0.1...</td>\n      <td>[-0.06564694978218584, 0.16773359051108175, 0....</td>\n      <td>[0.0028043567225936416, 0.08737022878496849, 0...</td>\n      <td>[0.020681329515193053, 0.09606176851262922, 0....</td>\n    </tr>\n    <tr>\n      <th>402656</th>\n      <td>1538045212</td>\n      <td>1260308147</td>\n      <td>1</td>\n      <td>[-0.06026564376806319, 0.06466471119274592, 0....</td>\n      <td>[-0.06026564376806319, 0.06466471119274592, 0....</td>\n      <td>[0.013333064400492953, 0.04302197479255666, -0...</td>\n      <td>[0.027618132749886747, 0.043863263628167844, 0...</td>\n    </tr>\n    <tr>\n      <th>603778</th>\n      <td>624543430</td>\n      <td>643995467</td>\n      <td>1</td>\n      <td>[-0.10795983864026687, 0.11143058981914807, 0....</td>\n      <td>[-0.10795983864026687, 0.11143058981914807, 0....</td>\n      <td>[-0.1444987461840761, 0.012642815029058228, 0....</td>\n      <td>[-0.1444987461840761, 0.012642815029058228, 0....</td>\n    </tr>\n    <tr>\n      <th>990986</th>\n      <td>549717139</td>\n      <td>770507056</td>\n      <td>0</td>\n      <td>[-0.05780336186312863, 0.10871770418453706, 0....</td>\n      <td>[-0.10695534967774047, 0.10274007141308132, 0....</td>\n      <td>[-0.11563188984453558, -0.0300171418274068, 0....</td>\n      <td>[-0.14109791208323372, -0.09175968737285321, 0...</td>\n    </tr>\n    <tr>\n      <th>409047</th>\n      <td>649797520</td>\n      <td>879623472</td>\n      <td>0</td>\n      <td>[-0.12076712039491183, 0.07852172420462776, 0....</td>\n      <td>[-0.06267111313383358, 0.10102431998347174, 0....</td>\n      <td>[0.026176950310800598, 0.07444865815055808, 0....</td>\n      <td>[0.09139589627693984, 0.0473513305769275, -0.0...</td>\n    </tr>\n    <tr>\n      <th>702968</th>\n      <td>520370280</td>\n      <td>519611246</td>\n      <td>0</td>\n      <td>[-0.11797401983607729, 0.10413861452454366, 0....</td>\n      <td>[-0.10429043371336227, 0.15591572990719407, 0....</td>\n      <td>[0.15868388728853233, -0.12677397737166818, 0....</td>\n      <td>[0.15863902201190758, -0.12766167187419677, 0....</td>\n    </tr>\n    <tr>\n      <th>159390</th>\n      <td>1378854094</td>\n      <td>1479216673</td>\n      <td>0</td>\n      <td>[-0.15941642796337185, 0.09956636748152727, 0....</td>\n      <td>[-0.14322157790637444, 0.09359274834060663, 0....</td>\n      <td>[-0.09069716768735359, 0.0842488682283678, 0.0...</td>\n      <td>[-0.034625219577910406, 0.03753115899603996, -...</td>\n    </tr>\n    <tr>\n      <th>669154</th>\n      <td>559634167</td>\n      <td>1068285114</td>\n      <td>1</td>\n      <td>[-0.19295330385439521, 0.1060335238520659, 0.1...</td>\n      <td>[-0.1421385807586221, 0.10561073868838532, 0.1...</td>\n      <td>[0.095310759569876, 0.020021074148214812, -0.0...</td>\n      <td>[0.095310759569876, 0.020021074148214812, -0.0...</td>\n    </tr>\n    <tr>\n      <th>962862</th>\n      <td>1198430731</td>\n      <td>1320472216</td>\n      <td>1</td>\n      <td>[-0.16471791832722063, 0.13700978647391915, 0....</td>\n      <td>[-0.14285859017240532, 0.10894745194399306, 0....</td>\n      <td>[0.15620091271218106, -0.09836465236844918, -0...</td>\n      <td>[0.15622335486895064, -0.09833839443225638, -0...</td>\n    </tr>\n    <tr>\n      <th>188630</th>\n      <td>1050279370</td>\n      <td>1057322612</td>\n      <td>1</td>\n      <td>[-0.10568100505825985, 0.11672703286742532, 0....</td>\n      <td>[-0.10568100505825985, 0.11672703286742532, 0....</td>\n      <td>[0.09069506140904349, -0.04152337680339512, 0....</td>\n      <td>[0.09069506140904349, -0.04152337680339512, 0....</td>\n    </tr>\n    <tr>\n      <th>154425</th>\n      <td>1434804241</td>\n      <td>1434785206</td>\n      <td>0</td>\n      <td>[-0.1652294224511481, 0.1664451347303791, 0.13...</td>\n      <td>[-0.1601871410059333, 0.1503487376351924, 0.09...</td>\n      <td>[0.03214607775076375, 0.07641763451645232, -0....</td>\n      <td>[-0.024973559088412093, 0.10590774794461999, -...</td>\n    </tr>\n    <tr>\n      <th>405418</th>\n      <td>1446269122</td>\n      <td>1451536066</td>\n      <td>0</td>\n      <td>[-0.12249209733134717, 0.14965457011623776, 0....</td>\n      <td>[-0.12449717778328495, 0.1161154961997902, 0.0...</td>\n      <td>[-0.024547983898651593, 0.011389824063666409, ...</td>\n      <td>[-0.022082243277048247, -0.07765947746200852, ...</td>\n    </tr>\n    <tr>\n      <th>490819</th>\n      <td>147167695</td>\n      <td>656496769</td>\n      <td>0</td>\n      <td>[-0.09343938430993842, 0.16067352633038368, 0....</td>\n      <td>[-0.1216826261401168, 0.14150558613359662, 0.1...</td>\n      <td>[0.05849160579397191, -0.01331073934266062, 0....</td>\n      <td>[0.05849160579397191, -0.01331073934266062, 0....</td>\n    </tr>\n    <tr>\n      <th>162204</th>\n      <td>862443433</td>\n      <td>862986797</td>\n      <td>0</td>\n      <td>[-0.1644600735300163, 0.14104117149291884, 0.1...</td>\n      <td>[-0.1320074528937805, 0.094743007297204, 0.175...</td>\n      <td>[-0.07075008790592768, 0.09369094553234529, 0....</td>\n      <td>[-0.12192321576079582, 0.11373922332080083, 0....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"for col in [\"name_bert_64_1\", \"name_bert_64_2\", \"main_pic_embeddings_resnet_v1_1\", \"main_pic_embeddings_resnet_v1_2\"]:\n    print(f\"Проверка {col}: {sampled_df[col].apply(lambda x: isinstance(x, np.ndarray)).all()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:53:56.421731Z","iopub.execute_input":"2024-12-27T18:53:56.422145Z","iopub.status.idle":"2024-12-27T18:53:56.430325Z","shell.execute_reply.started":"2024-12-27T18:53:56.422105Z","shell.execute_reply":"2024-12-27T18:53:56.428801Z"}},"outputs":[{"name":"stdout","text":"Проверка name_bert_64_1: True\nПроверка name_bert_64_2: True\nПроверка main_pic_embeddings_resnet_v1_1: True\nПроверка main_pic_embeddings_resnet_v1_2: True\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"for col in [\"name_bert_64_1\", \"name_bert_64_2\", \"main_pic_embeddings_resnet_v1_1\", \"main_pic_embeddings_resnet_v1_2\"]:\n    print(f\"{col}: размеры массивов\")\n    print(sampled_df[col].apply(lambda x: x.shape if isinstance(x, np.ndarray) else \"Некорректное значение\").value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:53:44.569950Z","iopub.execute_input":"2024-12-27T18:53:44.570420Z","iopub.status.idle":"2024-12-27T18:53:44.583698Z","shell.execute_reply.started":"2024-12-27T18:53:44.570387Z","shell.execute_reply":"2024-12-27T18:53:44.580972Z"}},"outputs":[{"name":"stdout","text":"name_bert_64_1: размеры массивов\nname_bert_64_1\n(64,)    15\nName: count, dtype: int64\nname_bert_64_2: размеры массивов\nname_bert_64_2\n(64,)    15\nName: count, dtype: int64\nmain_pic_embeddings_resnet_v1_1: размеры массивов\nmain_pic_embeddings_resnet_v1_1\n(128,)    15\nName: count, dtype: int64\nmain_pic_embeddings_resnet_v1_2: размеры массивов\nmain_pic_embeddings_resnet_v1_2\n(128,)    15\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"text_emb1 = torch.tensor(sampled_df[\"name_bert_64_1\"].tolist(), dtype=torch.float32)\ntext_emb2 = torch.tensor(sampled_df[\"name_bert_64_2\"].tolist(), dtype=torch.float32)\nimg_emb1 = torch.tensor(sampled_df[\"main_pic_embeddings_resnet_v1_1\"].tolist(), dtype=torch.float32)\nimg_emb2 = torch.tensor(sampled_df[\"main_pic_embeddings_resnet_v1_2\"].tolist(), dtype=torch.float32)\n\n# Прогоняем данные через модель\nmodel.eval()  # Устанавливаем модель в режим оценки\nwith torch.no_grad():\n    outputs = model(text_emb1, img_emb1, text_emb2, img_emb2)\n    probas = outputs.squeeze().cpu().numpy()\n    predictions = (outputs > 0.5).float().squeeze().cpu().numpy()\n\n# Добавляем предсказания в DataFrame\nsampled_df[\"predictions\"] = predictions\nsampled_df[\"probas\"] = probas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:58:38.637484Z","iopub.execute_input":"2024-12-27T18:58:38.637908Z","iopub.status.idle":"2024-12-27T18:58:38.650963Z","shell.execute_reply.started":"2024-12-27T18:58:38.637877Z","shell.execute_reply":"2024-12-27T18:58:38.649543Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"sampled_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:58:41.929048Z","iopub.execute_input":"2024-12-27T18:58:41.929397Z","iopub.status.idle":"2024-12-27T18:58:41.998447Z","shell.execute_reply.started":"2024-12-27T18:58:41.929370Z","shell.execute_reply":"2024-12-27T18:58:41.997420Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"        variantid1  variantid2  target  \\\n586673   447116673   447276570       0   \n110057   588412848  1169982188       0   \n402656  1538045212  1260308147       1   \n603778   624543430   643995467       1   \n990986   549717139   770507056       0   \n409047   649797520   879623472       0   \n702968   520370280   519611246       0   \n159390  1378854094  1479216673       0   \n669154   559634167  1068285114       1   \n962862  1198430731  1320472216       1   \n188630  1050279370  1057322612       1   \n154425  1434804241  1434785206       0   \n405418  1446269122  1451536066       0   \n490819   147167695   656496769       0   \n162204   862443433   862986797       0   \n\n                                           name_bert_64_1  \\\n586673  [-0.11546845693788657, 0.11879767000499351, 0....   \n110057  [-0.08414979233219054, 0.1594500221920774, 0.1...   \n402656  [-0.06026564376806319, 0.06466471119274592, 0....   \n603778  [-0.10795983864026687, 0.11143058981914807, 0....   \n990986  [-0.05780336186312863, 0.10871770418453706, 0....   \n409047  [-0.12076712039491183, 0.07852172420462776, 0....   \n702968  [-0.11797401983607729, 0.10413861452454366, 0....   \n159390  [-0.15941642796337185, 0.09956636748152727, 0....   \n669154  [-0.19295330385439521, 0.1060335238520659, 0.1...   \n962862  [-0.16471791832722063, 0.13700978647391915, 0....   \n188630  [-0.10568100505825985, 0.11672703286742532, 0....   \n154425  [-0.1652294224511481, 0.1664451347303791, 0.13...   \n405418  [-0.12249209733134717, 0.14965457011623776, 0....   \n490819  [-0.09343938430993842, 0.16067352633038368, 0....   \n162204  [-0.1644600735300163, 0.14104117149291884, 0.1...   \n\n                                           name_bert_64_2  \\\n586673  [-0.12460829199407925, 0.12305943289675993, 0....   \n110057  [-0.06564694978218584, 0.16773359051108175, 0....   \n402656  [-0.06026564376806319, 0.06466471119274592, 0....   \n603778  [-0.10795983864026687, 0.11143058981914807, 0....   \n990986  [-0.10695534967774047, 0.10274007141308132, 0....   \n409047  [-0.06267111313383358, 0.10102431998347174, 0....   \n702968  [-0.10429043371336227, 0.15591572990719407, 0....   \n159390  [-0.14322157790637444, 0.09359274834060663, 0....   \n669154  [-0.1421385807586221, 0.10561073868838532, 0.1...   \n962862  [-0.14285859017240532, 0.10894745194399306, 0....   \n188630  [-0.10568100505825985, 0.11672703286742532, 0....   \n154425  [-0.1601871410059333, 0.1503487376351924, 0.09...   \n405418  [-0.12449717778328495, 0.1161154961997902, 0.0...   \n490819  [-0.1216826261401168, 0.14150558613359662, 0.1...   \n162204  [-0.1320074528937805, 0.094743007297204, 0.175...   \n\n                          main_pic_embeddings_resnet_v1_1  \\\n586673  [-0.052273153188848204, 0.10378567635655774, -...   \n110057  [0.0028043567225936416, 0.08737022878496849, 0...   \n402656  [0.013333064400492953, 0.04302197479255666, -0...   \n603778  [-0.1444987461840761, 0.012642815029058228, 0....   \n990986  [-0.11563188984453558, -0.0300171418274068, 0....   \n409047  [0.026176950310800598, 0.07444865815055808, 0....   \n702968  [0.15868388728853233, -0.12677397737166818, 0....   \n159390  [-0.09069716768735359, 0.0842488682283678, 0.0...   \n669154  [0.095310759569876, 0.020021074148214812, -0.0...   \n962862  [0.15620091271218106, -0.09836465236844918, -0...   \n188630  [0.09069506140904349, -0.04152337680339512, 0....   \n154425  [0.03214607775076375, 0.07641763451645232, -0....   \n405418  [-0.024547983898651593, 0.011389824063666409, ...   \n490819  [0.05849160579397191, -0.01331073934266062, 0....   \n162204  [-0.07075008790592768, 0.09369094553234529, 0....   \n\n                          main_pic_embeddings_resnet_v1_2  predictions  \\\n586673  [-0.052273153188848204, 0.10378567635655774, -...          0.0   \n110057  [0.020681329515193053, 0.09606176851262922, 0....          1.0   \n402656  [0.027618132749886747, 0.043863263628167844, 0...          1.0   \n603778  [-0.1444987461840761, 0.012642815029058228, 0....          1.0   \n990986  [-0.14109791208323372, -0.09175968737285321, 0...          0.0   \n409047  [0.09139589627693984, 0.0473513305769275, -0.0...          0.0   \n702968  [0.15863902201190758, -0.12766167187419677, 0....          0.0   \n159390  [-0.034625219577910406, 0.03753115899603996, -...          0.0   \n669154  [0.095310759569876, 0.020021074148214812, -0.0...          0.0   \n962862  [0.15622335486895064, -0.09833839443225638, -0...          1.0   \n188630  [0.09069506140904349, -0.04152337680339512, 0....          1.0   \n154425  [-0.024973559088412093, 0.10590774794461999, -...          0.0   \n405418  [-0.022082243277048247, -0.07765947746200852, ...          0.0   \n490819  [0.05849160579397191, -0.01331073934266062, 0....          0.0   \n162204  [-0.12192321576079582, 0.11373922332080083, 0....          0.0   \n\n          probas  \n586673  0.165524  \n110057  0.662866  \n402656  0.726535  \n603778  0.821573  \n990986  0.135100  \n409047  0.008954  \n702968  0.038423  \n159390  0.393728  \n669154  0.490262  \n962862  0.595072  \n188630  0.986809  \n154425  0.216991  \n405418  0.145977  \n490819  0.018681  \n162204  0.023355  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n      <th>target</th>\n      <th>name_bert_64_1</th>\n      <th>name_bert_64_2</th>\n      <th>main_pic_embeddings_resnet_v1_1</th>\n      <th>main_pic_embeddings_resnet_v1_2</th>\n      <th>predictions</th>\n      <th>probas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>586673</th>\n      <td>447116673</td>\n      <td>447276570</td>\n      <td>0</td>\n      <td>[-0.11546845693788657, 0.11879767000499351, 0....</td>\n      <td>[-0.12460829199407925, 0.12305943289675993, 0....</td>\n      <td>[-0.052273153188848204, 0.10378567635655774, -...</td>\n      <td>[-0.052273153188848204, 0.10378567635655774, -...</td>\n      <td>0.0</td>\n      <td>0.165524</td>\n    </tr>\n    <tr>\n      <th>110057</th>\n      <td>588412848</td>\n      <td>1169982188</td>\n      <td>0</td>\n      <td>[-0.08414979233219054, 0.1594500221920774, 0.1...</td>\n      <td>[-0.06564694978218584, 0.16773359051108175, 0....</td>\n      <td>[0.0028043567225936416, 0.08737022878496849, 0...</td>\n      <td>[0.020681329515193053, 0.09606176851262922, 0....</td>\n      <td>1.0</td>\n      <td>0.662866</td>\n    </tr>\n    <tr>\n      <th>402656</th>\n      <td>1538045212</td>\n      <td>1260308147</td>\n      <td>1</td>\n      <td>[-0.06026564376806319, 0.06466471119274592, 0....</td>\n      <td>[-0.06026564376806319, 0.06466471119274592, 0....</td>\n      <td>[0.013333064400492953, 0.04302197479255666, -0...</td>\n      <td>[0.027618132749886747, 0.043863263628167844, 0...</td>\n      <td>1.0</td>\n      <td>0.726535</td>\n    </tr>\n    <tr>\n      <th>603778</th>\n      <td>624543430</td>\n      <td>643995467</td>\n      <td>1</td>\n      <td>[-0.10795983864026687, 0.11143058981914807, 0....</td>\n      <td>[-0.10795983864026687, 0.11143058981914807, 0....</td>\n      <td>[-0.1444987461840761, 0.012642815029058228, 0....</td>\n      <td>[-0.1444987461840761, 0.012642815029058228, 0....</td>\n      <td>1.0</td>\n      <td>0.821573</td>\n    </tr>\n    <tr>\n      <th>990986</th>\n      <td>549717139</td>\n      <td>770507056</td>\n      <td>0</td>\n      <td>[-0.05780336186312863, 0.10871770418453706, 0....</td>\n      <td>[-0.10695534967774047, 0.10274007141308132, 0....</td>\n      <td>[-0.11563188984453558, -0.0300171418274068, 0....</td>\n      <td>[-0.14109791208323372, -0.09175968737285321, 0...</td>\n      <td>0.0</td>\n      <td>0.135100</td>\n    </tr>\n    <tr>\n      <th>409047</th>\n      <td>649797520</td>\n      <td>879623472</td>\n      <td>0</td>\n      <td>[-0.12076712039491183, 0.07852172420462776, 0....</td>\n      <td>[-0.06267111313383358, 0.10102431998347174, 0....</td>\n      <td>[0.026176950310800598, 0.07444865815055808, 0....</td>\n      <td>[0.09139589627693984, 0.0473513305769275, -0.0...</td>\n      <td>0.0</td>\n      <td>0.008954</td>\n    </tr>\n    <tr>\n      <th>702968</th>\n      <td>520370280</td>\n      <td>519611246</td>\n      <td>0</td>\n      <td>[-0.11797401983607729, 0.10413861452454366, 0....</td>\n      <td>[-0.10429043371336227, 0.15591572990719407, 0....</td>\n      <td>[0.15868388728853233, -0.12677397737166818, 0....</td>\n      <td>[0.15863902201190758, -0.12766167187419677, 0....</td>\n      <td>0.0</td>\n      <td>0.038423</td>\n    </tr>\n    <tr>\n      <th>159390</th>\n      <td>1378854094</td>\n      <td>1479216673</td>\n      <td>0</td>\n      <td>[-0.15941642796337185, 0.09956636748152727, 0....</td>\n      <td>[-0.14322157790637444, 0.09359274834060663, 0....</td>\n      <td>[-0.09069716768735359, 0.0842488682283678, 0.0...</td>\n      <td>[-0.034625219577910406, 0.03753115899603996, -...</td>\n      <td>0.0</td>\n      <td>0.393728</td>\n    </tr>\n    <tr>\n      <th>669154</th>\n      <td>559634167</td>\n      <td>1068285114</td>\n      <td>1</td>\n      <td>[-0.19295330385439521, 0.1060335238520659, 0.1...</td>\n      <td>[-0.1421385807586221, 0.10561073868838532, 0.1...</td>\n      <td>[0.095310759569876, 0.020021074148214812, -0.0...</td>\n      <td>[0.095310759569876, 0.020021074148214812, -0.0...</td>\n      <td>0.0</td>\n      <td>0.490262</td>\n    </tr>\n    <tr>\n      <th>962862</th>\n      <td>1198430731</td>\n      <td>1320472216</td>\n      <td>1</td>\n      <td>[-0.16471791832722063, 0.13700978647391915, 0....</td>\n      <td>[-0.14285859017240532, 0.10894745194399306, 0....</td>\n      <td>[0.15620091271218106, -0.09836465236844918, -0...</td>\n      <td>[0.15622335486895064, -0.09833839443225638, -0...</td>\n      <td>1.0</td>\n      <td>0.595072</td>\n    </tr>\n    <tr>\n      <th>188630</th>\n      <td>1050279370</td>\n      <td>1057322612</td>\n      <td>1</td>\n      <td>[-0.10568100505825985, 0.11672703286742532, 0....</td>\n      <td>[-0.10568100505825985, 0.11672703286742532, 0....</td>\n      <td>[0.09069506140904349, -0.04152337680339512, 0....</td>\n      <td>[0.09069506140904349, -0.04152337680339512, 0....</td>\n      <td>1.0</td>\n      <td>0.986809</td>\n    </tr>\n    <tr>\n      <th>154425</th>\n      <td>1434804241</td>\n      <td>1434785206</td>\n      <td>0</td>\n      <td>[-0.1652294224511481, 0.1664451347303791, 0.13...</td>\n      <td>[-0.1601871410059333, 0.1503487376351924, 0.09...</td>\n      <td>[0.03214607775076375, 0.07641763451645232, -0....</td>\n      <td>[-0.024973559088412093, 0.10590774794461999, -...</td>\n      <td>0.0</td>\n      <td>0.216991</td>\n    </tr>\n    <tr>\n      <th>405418</th>\n      <td>1446269122</td>\n      <td>1451536066</td>\n      <td>0</td>\n      <td>[-0.12249209733134717, 0.14965457011623776, 0....</td>\n      <td>[-0.12449717778328495, 0.1161154961997902, 0.0...</td>\n      <td>[-0.024547983898651593, 0.011389824063666409, ...</td>\n      <td>[-0.022082243277048247, -0.07765947746200852, ...</td>\n      <td>0.0</td>\n      <td>0.145977</td>\n    </tr>\n    <tr>\n      <th>490819</th>\n      <td>147167695</td>\n      <td>656496769</td>\n      <td>0</td>\n      <td>[-0.09343938430993842, 0.16067352633038368, 0....</td>\n      <td>[-0.1216826261401168, 0.14150558613359662, 0.1...</td>\n      <td>[0.05849160579397191, -0.01331073934266062, 0....</td>\n      <td>[0.05849160579397191, -0.01331073934266062, 0....</td>\n      <td>0.0</td>\n      <td>0.018681</td>\n    </tr>\n    <tr>\n      <th>162204</th>\n      <td>862443433</td>\n      <td>862986797</td>\n      <td>0</td>\n      <td>[-0.1644600735300163, 0.14104117149291884, 0.1...</td>\n      <td>[-0.1320074528937805, 0.094743007297204, 0.175...</td>\n      <td>[-0.07075008790592768, 0.09369094553234529, 0....</td>\n      <td>[-0.12192321576079582, 0.11373922332080083, 0....</td>\n      <td>0.0</td>\n      <td>0.023355</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"def make_predictions(model, sampled_df):\n    # Подготовка данных для предсказания\n    text_emb1 = torch.tensor(sampled_df[\"name_bert_64_1\"].tolist(), dtype=torch.float32)\n    text_emb2 = torch.tensor(sampled_df[\"name_bert_64_2\"].tolist(), dtype=torch.float32)\n    img_emb1 = torch.tensor(sampled_df[\"main_pic_embeddings_resnet_v1_1\"].tolist(), dtype=torch.float32)\n    img_emb2 = torch.tensor(sampled_df[\"main_pic_embeddings_resnet_v1_2\"].tolist(), dtype=torch.float32)\n\n    # Прогоняем данные через модель\n    model.eval()  # Устанавливаем модель в режим оценки\n    with torch.no_grad():\n        outputs = model(text_emb1, img_emb1, text_emb2, img_emb2)\n        probas = outputs.squeeze().cpu().numpy()\n        predictions = (outputs > 0.5).float().squeeze().cpu().numpy()\n\n    # Добавляем предсказания в DataFrame\n    sampled_df[\"predictions\"] = predictions\n    sampled_df[\"probas\"] = probas\n    \n    return sampled_df\n\n# Применяем функцию для получения предсказаний\nsampled_df = make_predictions(model, sampled_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:06:23.461190Z","iopub.execute_input":"2024-12-27T19:06:23.461602Z","iopub.status.idle":"2024-12-27T19:06:23.474140Z","shell.execute_reply.started":"2024-12-27T19:06:23.461567Z","shell.execute_reply":"2024-12-27T19:06:23.473131Z"}},"outputs":[],"execution_count":54}]}